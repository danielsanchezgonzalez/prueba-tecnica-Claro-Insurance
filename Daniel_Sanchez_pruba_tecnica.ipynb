import pandas as pd
import numpy as np
import random
from gensim.models import Word2Vec
import sqlite3 as sql
from tqdm import tqdm
from sklearn.neighbors import NearestNeighbors



# Creates an object which creates a pandas DataFrame for each sheet of the file in the path
class DataBase:
    def __init__(self, path_to_file):
        self.file = pd.ExcelFile(path_to_file)
        self.sheets = self.file.sheet_names
        self.data_samples = pd.read_excel(self.file, sheet_name = self.sheets[0])
        self.variables = pd.read_excel(self.file, sheet_name = self.sheets[1])
        self.details = pd.read_excel(self.file, sheet_name = self.sheets[2])
        self.products = pd.read_excel(self.file, sheet_name = self.sheets[3])
        self.clients = pd.read_excel(self.file, sheet_name = self.sheets[4])
        self.orders = pd.read_excel(self.file, sheet_name = self.sheets[5])

    # This functions queries from the tables in an xlsx file and return rfm table
    def rfm_segmentation(self):
        # Get pandas dataframes
        details = self.details
        clients = self.clients
        orders = self.orders
        # Establish a connection
        cx = sql.connect('rfm_segmentation.db')
        # From pandas dataframe to sql table
        details.to_sql('details', cx)
        clients.to_sql('clients', cx)
        orders.to_sql('orders', cx)
        # Queries
        recency_query = """SELECT c.CUSTOMERNAME AS Recency, MAX(datetime(CAST(YEAR_ID AS TEXT) || '-' || CASE WHEN MONTH_ID < 10 THEN '0' || CAST(MONTH_ID AS TEXT) ELSE CAST(MONTH_ID AS TEXT) END || '-' || CASE WHEN DAY_ID < 10 THEN '0' || CAST(DAY_ID AS TEXT) ELSE CAST(DAY_ID AS TEXT) END))
                           FROM orders AS o 
                           INNER JOIN details AS d on o.ORDERNUMBER = d.ORDERNUMBER 
                           INNER JOIN clients AS c ON d.ID_Cliente = c.ID_Cliente
                           GROUP BY d.ID_Cliente
                           ORDER BY datetime(CAST(YEAR_ID AS TEXT) || '-' || CASE WHEN MONTH_ID < 10 THEN '0' || CAST(MONTH_ID AS TEXT) ELSE CAST(MONTH_ID AS TEXT) END || '-' || CASE WHEN DAY_ID < 10 THEN '0' || CAST(DAY_ID AS TEXT) ELSE CAST(DAY_ID AS TEXT) END) DESC
                           """
        frequency_query = """SELECT c.CUSTOMERNAME AS Frequency FROM clients as c 
                             LEFT JOIN details as d ON c.ID_Cliente = d.ID_Cliente 
                             GROUP BY c.CUSTOMERNAME 
                             ORDER BY COUNT(c.CUSTOMERNAME) DESC
                             """ 
        money_query = """SELECT c.CUSTOMERNAME AS Money FROM clients as c 
                         LEFT JOIN details as d ON c.ID_Cliente = d.ID_Cliente 
                         GROUP BY c.ID_Cliente 
                         ORDER BY SUM(SALES) DESC
                        """
        # Queries into pandas dataframe
        recency = pd.read_sql(recency_query, cx)
        frequency = pd.read_sql(frequency_query, cx)
        money = pd.read_sql(money_query, cx)
        # Close session
        cx.close()
        # Merging the dataframes into a unique pandas dataframe
        rfm_table = pd.concat([recency.iloc[:, 0], frequency, money], axis = 1)
        print(rfm_table, file=open("output.txt", "a"))
        return rfm_table

    def groups(self, rfm_table):
        # Create list of rfm ranks and indexes which divide them in groups
        index = list(range(0, rfm_table.shape[0], round(rfm_table.shape[0]/5)))
        recency = rfm_table['Recency'].tolist()
        frequency = rfm_table['Frequency'].tolist()
        money = rfm_table['Money'].tolist()
        # Empty lists for
        potenciales = []
        perdidos = []
        derrochadores = []
        leales = []
        nuevos = []
        # Looping across list of clients
        for client in recency:
            # When client is in the top two groups of each rank, save it into potentials clients
            if client in recency[index[0]:index[2]] and client in frequency[index[0]:index[2]] and client in money[index[0]:index[2]]:
                potenciales.append(client)
            # When client is in the bottom tree groups of each rank, save it into missed clients
            elif client in recency[index[2]:] and client in frequency[index[2]:] and client in money[index[2]:]:
                perdidos.append(client)
            # When client is in the top group of money, save it into spenders
            elif client in money[:index[1]]:
                derrochadores.append(client)
            # When client is in the top two groups of frequency, save it into loyals clients
            elif client in frequency[index[0]:index[2]]:
                leales.append(client)
            # When client is in the top group of recency sabe it into newbies clients
            elif client in recency[index[0]:index[2]]:
                nuevos.append(client)
            
        groups = {'Potenciales': potenciales, 'Perdidos': perdidos, 'Derrochadores': derrochadores,
                   'Leales': leales, 'Nuevos': nuevos}
        for i in groups.keys():
            print(i + ':')
            for j in groups[i]:
                print(j)
            print('\n\n\n')
        return groups

    def word2vec_suggestions(self, n_combos):
        # Get the relevant dataframe
        df = self.details
        # Make sure object variables are stings
        for var in df.columns.tolist():
            if df[var].dtype == 'object':
                df[var] = df[var].astype(str)
        orders = df['ORDERNUMBER'].unique().tolist()
        random.shuffle(orders)
        orders_train = [orders[i] for i in range(round(1*len(orders)))]
        # SPliting into training and validation 
        train_df = df[df['ORDERNUMBER'].isin(orders_train)]
        validation_df = df[~df['ORDERNUMBER'].isin(orders_train)]
        # Getting products by orders for training and validation sets
        purchases_train = []   
        for i in orders_train:
            temp = train_df[train_df['ORDERNUMBER'] == i]['PRODUCTCODE'].tolist()
            purchases_train.append(temp)
            
        purchases_val = []
        for i in validation_df['ORDERNUMBER'].unique():
            temp = validation_df[validation_df['ORDERNUMBER'] == i]['PRODUCTCODE'].tolist()
            purchases_val.append(temp)
        # Building a word2vec model
        model = Word2Vec(window = n_combos + 1, sg = 1, compute_loss = True, hs = 0, negative = 10, alpha = 0.03, 
                         min_alpha = 0.0007, seed = 14)
        model.build_vocab(purchases_train, progress_per=20)
        model.train(purchases_train, total_examples = model.corpus_count, epochs = 10, report_delay = 1)
        # Getting the most and least sold product
        products = train_df['PRODUCTCODE']
        products = products.drop_duplicates(keep = "last")
        product_by_sales = df[['PRODUCTCODE', 'SALES']].groupby('PRODUCTCODE').sum().sort_values('SALES').reset_index()
        highest_sales = product_by_sales.iloc[0, 0]
        lowest_sales = product_by_sales.iloc[-1, 0]
        # Function for predicting baskets of goods containing one product
        def similar_products(v, n = n_combos):
            return model.wv.similar_by_vector(v, topn = n + 1)[1:]
       # Basket of goods for the highest and lowest sold products     
        list_h = similar_products(highest_sales)
        list_l = similar_products(lowest_sales)
        # Printing sugestions
        print('For Word2Vec:\nIf a costumer buys', highest_sales, 'they should buy (most sold item): ')
        for i in range(len(list_h)):
            print(list_h[i][0])
        print('\n')
        print('If a costumer buys', lowest_sales, 'they should buy (least sold item): ')
        for i in range(len(list_l)):
            print(list_l[i][0])
        print('\n')

    def knn_suggestion(self, n_combos):
        # Get the relevant dataframe
        df = pd.read_excel('/home/daniel/Claro Insurance/sales_data_sample (1).xlsx', sheet_name = 'DetalleOrden')
        product_by_sales = df[['PRODUCTCODE', 'SALES']].groupby('PRODUCTCODE').sum().sort_values('SALES').reset_index()
        highest_sales = product_by_sales.iloc[0, 0]
        lowest_sales = product_by_sales.iloc[-1, 0]
        # List products and orders
        orders = df["ORDERNUMBER"].unique().tolist()
        products = df["PRODUCTCODE"].unique().tolist()
        # Empty dictionary to build dataframe
        dictionary = {orders[i]: [i] for i in range(len(orders))}
        # Building a matrix of orders x products shape 
        for i in range(len(orders)):
            products_in_order = df[df['ORDERNUMBER'] == orders[i]]['PRODUCTCODE'].tolist()
            quantities_in_order = df[df['ORDERNUMBER'] == orders[i]]['QUANTITYORDERED'].tolist()
            order_dictionary = {products_in_order[j]: quantities_in_order[j] for j in range(len(products_in_order))}
            dictionary[orders[i]] = order_dictionary
        # DataFrame from matrix
        df = pd.DataFrame(dictionary).fillna(0)
        # Building and training the model
        model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute', n_neighbors = 3, n_jobs = -1)
        model_knn.fit(df)
        # Get index number of highest and lowest sold products in list
        high_index = products.index(highest_sales)
        low_index = products.index(lowest_sales)
        # For predictions, building array with integer at index basket 
        highest = np.zeros((1, len(orders)))
        highest[0, high_index] = 1
        lowest = np.zeros((1, len(orders)))
        lowest[0, low_index] = 1
        # Predict
        distances_h, indices_h = model_knn.kneighbors(highest, n_neighbors = n_combos)
        distances_l, indices_l = model_knn.kneighbors(lowest, n_neighbors = n_combos)
        # Print results
        indices_h = np.squeeze(indices_h)
        indices_l = np.squeeze(indices_l)
        print('For KNN algorithm:\nIf a costumer buys', highest_sales, 'they should buy (most sold item): ')
        for k in range(n_combos):
            print(products[indices_h[k]])
        print('\n')
        print('If a costumer buys', lowest_sales, 'they should buy (least sold item): ')
        for k in range(n_combos):
            print(products[indices_l[k]])
        print('\n')
        

        
# Create instance of DataBase object
cars_and_motorbikes = DataBase('sales_data_sample (1).xlsx') # IMPORTANTE: Verificar que la direccion del archivos xlsx sea correcta
# Returns rfm table from xlsx file
rfm_cars_and_motorbikes = cars_and_motorbikes.rfm_segmentation() # IMPORTANTE: Luego de correr la primera vez, SQLite3 genera un dataframe y es necesario eliminarlo si se desea correr de nuevo
grupos_dict = cars_and_motorbikes.groups(rfm_cars_and_motorbikes)
# Word 2 Vec model for product suggestion
cars_and_motorbikes.word2vec_suggestions(3)
# KNN model for product suggestion
cars_and_motorbikes.knn_suggestion(3)